---
layout: post
published: true
title: 왜 굳이 A/B 테스트인가요?
mathjax: false
featured: true
comments: true
headline: Why A/B testing?
categories: data
tags: abtest
---

![cover-image](/images/taking-notes.jpg)

요즘은 어딜 가든 A/B 테스트를 해야 한다는 말이 들리는 것 같습니다. 광고, 추천, 마케팅, UI, UX 등 다양한 분야에서 A/B 테스트에 대한 논의와 적용 방법에 대해서 이야기 하고 있습니다. 그런데 왜 굳이 A/B 테스트일까요? 다른 방법은 없는건가요? 왜 사람들은 실험을 잘 하면 성장할 수 있다고 확신에 가깝게 말하는 걸까요? 무엇인가 이론적인 근거가 있는 건지, 도대체 무슨 비밀이 있는 것인지 가볍게 살펴보겠습니다.

# Case : Office 365

마이크로소프트 오피스의 구독형 서비스인 Office 365의 사용자들을 대상으로 분석한 결과, **에러 메시지를 보거나 오류를 겪은 사람들의 이탈률이 더 낮았다**고 합니다. 그러면 에러를 더 많이 발생시키면 사람들의 이탈률이 낮아질까요? 

그렇지는 않을 겁니다. **데이터를 통해 확인할 수 있는 것은 상관관계이지 인과관계가 아닙니다.** 데이터 상에서 에러 메시지를 본 횟수와 이탈률 사이에는 분명 통계적으로 연관이 있습니다. 하지만 에러를 일부러 발생시킨다고 해서 이탈률이 더 낮아지진 않습니다. 실제로 이 경우는 에러와 이탈률 모두에 영향을 미치는 공통적인 원인, 바로 **서비스 사용량** 때문에 발생한 현상입니다. 오피스 365의 헤비 유저들은 서비스를 오래 사용하다 보니 자연스럽게 에러를 많이 경험하게 되었습니다. 에러 메시지를 많이 본 사람들 중에는 헤비 유저가 많고, 헤비 유저가 많이 포함되어 있으니 계산할 때 이탈률이 낮게 집계되는 겁니다.

# "상관관계는 인과관계가 아닙니다."

앞에서도 잠깐 언급되었던 말입니다. 혹시라도 통계 관련 수업을 들으셨다면 수업 시간에 들어보셨을지도 모르겠네요. 그래서 이게 도대체 무슨 말일까요?

**무엇인가 값을 바꿨을 때 직접적인 영향을 받아 변하는 것**이 있나요? 그렇다면 그걸 인과 관계라고 해보겠습니다. **인과 관계가 없더라도 변수들이 서로 영향을 주고 받는 경우**가 있습니다. 오피스 365 케이스에서는  `에러 ← 서비스사용량 → 이탈률` 의 형태로 영향을 주고 받습니다. 에러가 늘어난다고 이탈율이 낮아지지는 않겠지만, 헤비 유저가 많이 포함된 데이터를 보면 에러를 많이 볼수록 이탈률이 낮은 경향을 보이게 됩니다.

또, **인과 관계의 방향이 반대인 경우**도 있습니다. 상관관계에는 방향이 없지만, 인과관계에서는 "여기서 값을 바꿨더니 저기가 변했더라" 고 하는 방향성이 존재합니다. 사람들의 월급이 2배로 늘어서 소비도 2배로 늘었다는 행복한 상상을 해보겠습니다. 이걸 본 사람들이 따라서 돈을 두 배로 쓰기 시작합니다. 그렇게 한다고 월급이 두 배가 될까요? 지금은 직관적으로 상상할 수 있고, 어떻게 보면 극단적인 상황을 예로 들었기 때문에 바로 알아챌 수 있습니다. 하지만 데이터만으로 인과 관계의 방향을 잡아내는건 상당히 어려운 문제입니다. 해당 분야에 대한 도메인 지식이나 경험이 필요할 수도 있습니다.

가볍게 정리를 해볼까요? 두 변수가 데이터 상에서 연관성이 보인다면 **상관 관계**가 있다고 합니다. 그 중에서 A를 바꿨더니 B가 따라서 변하는 경우를 **인과 관계**라고 합니다. B를 바꾼다고 해서 A가 변할지는 알 수 없구요.

# 새로 도입한 개편안의 효과를 어떻게 알 수 있을까요?

기존 사이트 A안에서 구매 과정의 UX를 대폭 개선한 B안을 테스트해보기로 했습니다. 의도한 대로 된다면 구매전환율이 오를 것이라고 기대하고 있습니다. 이 때, 정말로 UX 개선이 구매전환율에 미치는 영향을 어떻게 확인할 수 있을까요? A안에서 B안으로 변경했을 때 구매전환율이 얼마나 변하는지 인과 효과를 구하고, 그 수치가 비즈니스적으로 의미있는 크기인지 판단하면 됩니다. 영향이 거의 없다면 개선안과 구매전환율 사이에 인과 관계가 있다고 보기는 어렵겠지요.

그렇다면 개선안이 구매전환율에 미치는 인과 효과는 어떻게 확인해야 할까요? 이상적인 경우 A안을 겪었을 때와 B안을 겪었을 때 각각 구매하는지 여부를 비교해야 합니다. 마블의 영화 어벤져스 엔드게임에서 닥터 스트레인지는 타임스톤을 통해 14,000,605개의 미래를 보고 최선의 경우의 수를 찾습니다. 만약 우리도 타임스톤을 쓸 수 있다면, **A안과 B안의 미래를 보고 와서 비교하는 것이 가장 이상적으로 인과 효과를 계산할 수 있는 방법입니다.** 하지만 **현실에서는 두 가지 방안 중에서 우리가 선택한 한 가지만 실제로 겪을 수 있습니다.** A안을 보고 그 뒤에 B안을 보는 것은 처음부터 B안을 보는 것과는 분명 다르니까요.

현실적으로 UX 개편의 인과 효과를 파악하려면 어떻게 해야 할까요? 앞서 말씀드렸듯, 모든 사람에 대한 각각의 효과를 파악하는 것은 어렵습니다. 하지만 **평균적인 효과**라면 어떨까요? 사람들을 두 그룹으로 쪼개서 한 그룹은 A안만, 다른 그룹은 B안만 보여주고 평균을 구해봅시다. 만약 **두 그룹의 특성이 모든 면에서 너무 비슷해서 어느 그룹인지 이름표를 붙이지 않을 경우 구분하기 어려울 정도**라면, 이제 두 그룹은 A안과 B안 중 하나를 본다는 점만 다르고 다른 모든 속성은 동일한 상태가 됩니다. **이 상태에서 두 그룹의 구매전환율을 비교**하면 우리가 원하던 UX 개편의 평균적인 효과를 알 수 있게 됩니다.

그런데 이 말대로라면 그 정도로 똑같은 2개 그룹을 만들어야 한다는 소리인데 그게 가능한가요? 네, 가능합니다. 고민할 것이 많긴 하지만요. 그리고 그게 A/B 테스트가 동작하는 방식입니다.

# RCT (Randomized Controlled Trial)

사람이 구분하기 어려울 정도로 비슷하게 2개 그룹으로 나누려면 어떻게 해야 할까요? 성별, 연령대, 모바일 기기, 관심사, 구매 성향 등등 우리가 고민해야 하는 기준들은 어마어마하게 많습니다. 이 모든 것들을 고려하면서 비율까지 일정하게 나누어지도록 쪼개는건 현실적으로 어려운 문제처럼 보입니다. 하지만 **어떤 사람이 A안과 B안 중 어디에 배정되어야 하는지를 동전 던지기로 결정**한다면 어떨까요? 50:50의 확률을 가지는 동전 던지기를 계속 반복하다 보면, 우리가 고려할 수 있는 모든 영역에 대해서 50:50에 가깝게 A안과 B안에 배정됩니다. 확률적으로 무조건 반반이니까요. 

이렇게 A/B안 배치를 랜덤한 방식을 통해 결정하는 실험 방식을 **Randomized Controlled Trial, 줄여서 RCT** 라고 합니다. 실험군과 대조군을 랜덤하게 배정하는 실험이라는 의미입니다. 잘 설계된 RCT 실험으로 A안과 B안을 구별하게 되면, 두 그룹간의 차이는 A안을 B안으로 변경하여 발생한 인과적인 효과로 볼 수 있습니다. 다시 말해, **A/B 테스트를 잘 설계해서 사용하면 A안 대신 B안을 선택했을 때 목표로 하는 지표에 얼마나 영향을 주는지 그 인과 효과를 데이터를 통해 측정**할 수 있게 됩니다. 이것이 바로 우리가 의사 결정을 위해 A/B 테스트를 사용하는 이유입니다.

# A/B 테스트는 만능인가요?

만능은 아니지만, 할 수만 있다면 가장 확실한 방법입니다. 하지만 A/B 테스트가 효과를 거두기 위해서는, 이론적인 바탕인 RCT를 만족하기 위한 조건을 계속 신경써야 합니다. 예를 들어, A군에 있는 사람이 B군에 영향을 미치거나, A군과 B군을 오고가는 사람이 생겨서는 안됩니다. 실험을 하는 동안에는 A군과 B군은 서로에게 영향을 미치지 않는 독립된 세계여야 합니다. 이러한 조건을 만족하지 못하면 실험 결과를 신뢰할 수 없게 됩니다. 온라인 서비스에서 실험을 수행할 때는 사용자의 A군/B군 여부가 변하거나, 나는 A군인데 친구가 B군의 링크/화면을 공유하는 등 예기치 못한 상황이 충분히 발생할 수 있습니다. 성공적으로 실험을 마무리하기 위해서는 실험을 설계하는 단계부터 이러한 문제를 미리 고민해서 예방해야 합니다.

또한, 여러 가지 이유로 A/B 테스트를 할 수 없는 상황이 존재합니다. 만약 테스트를 위해 준비해야 하는 비용이 과도하게 든다면 실험을 하기가 어려울 것입니다. 윤리적인 문제도 있습니다. 2012년 페이스북은 68만 9천여명의 사람들을 대상으로 뉴스피드에서 특정 감정과 관련된 단어를 제거하는 방식으로 사용자의 감정에 미치는 영향을 연구한 적이 있습니다. 논문이 발표되자 사람들을 대상으로 감정 조작을 한 것이 아니냐는 논란이 제기되었습니다.

이 외에도 A군과 B군이 어쩔 수 없이 서로에게 큰 영향을 줄 수밖에 없는 상황도 있습니다. 우버나 리프트같은 승차 공유 회사의 경우, 특정한 지역 내에서 탑승객들을 대상으로 매칭 알고리즘을 실험하면 드라이버가 A군과 B군을 모두 경험하게 되면서 영향을 주는 문제가 있었다고 합니다. 이런 경우에는 일반적인 형태의 A/B 테스트를 적용하는 것은 어려울 수 있습니다.

# 마무리

점점 많은 사람들이 데이터와 실험의 중요성을 깨닫고 업무에 도입하려고 합니다. 그런데 아직은 과정보다 성과에 집중해서 보는 시선이 많아 보입니다. A/B 테스트는 데이터만 넣으면 정확한 결과가 나오는 마법의 상자가 아닙니다. 세심하게 주의를 기울이지 않으면 시들어버리는 화초처럼 조심스럽게 접근해야 합니다. 잘못된 설계나 해석으로 인해 기껏 시간을 들여서 수집한 실험 결과를 신뢰할 수 없게 된다면 너무 안타깝지 않을까요? A/B 테스트가 어떤 원리를 통해 돌아가는지 알게 되면, 무엇을 조심해야 하는지 더 명확하게 판단할 수 있을 겁니다. 실험 결과를 신뢰할 수 있는 환경이 갖추어 진다면 그 때부터가 진짜 시작입니다.

# 참고자료

- [(Book) Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing](https://www.amazon.com/-/ko/dp/1108724264/){:target="_blank"}
- [Facebook emotion experiment sparks criticism](https://www.bbc.com/news/technology-28051930){:target="_blank"}
- [8 Common Pitfalls of Running A/B Tests](https://towardsdatascience.com/online-controlled-experiment-8-common-pitfalls-and-solutions-ea4488e5a82e){:target="_blank"}
